{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Input, BatchNormalization, MaxPooling2D,Flatten, Dense, Dropout, AveragePooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from utils import *\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Data Path\n",
    "with_mask_paths = [\"./data/data1/with_mask/with_mask_\" + str(i) + \".jpg\" for i in range(1, 4500 + 1)]\n",
    "without_mask_paths = [\"./data/data1/without_mask/without_mask_\" + str(i) + \".jpg\" for i in range(1, 4500 + 1)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Declare array for storing data & corresponding label\n",
    "data = []\n",
    "label = []\n",
    "\n",
    "# Load with_mask data\n",
    "load_data_with_label(path_arr=with_mask_paths,\n",
    "                     data_arr=data,\n",
    "                     label_arr=label,\n",
    "                     img_size=(224, 224, 3),\n",
    "                     _label = 1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Load Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load without_mask data\n",
    "load_data_with_label(path_arr=without_mask_paths,\n",
    "                     data_arr=data,\n",
    "                     label_arr=label,\n",
    "                     img_size=(224, 224, 3),\n",
    "                     _label = 0)\n",
    "\n",
    "print(\"Data Load Done!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n",
    "# Convert to numpy array\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "label = np.array(label)\n",
    "\n",
    "# Label one-hot encoding\n",
    "_lb = LabelBinarizer()\n",
    "\n",
    "label = _lb.fit_transform(label)\n",
    "label = to_categorical(label)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\n",
    "# Split data to train data and test data\n",
    "(train_X, test_X, train_Y, test_Y) = train_test_split(data, label,\n",
    "                                                      test_size=0.15,\n",
    "                                                      random_state=777,\n",
    "                                                      shuffle=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\n",
    "# Make CNN Model\n",
    "CNN = Sequential([\n",
    "    Input(shape=(224, 224, 3)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (3, 3), padding='SAME', activation='relu',\n",
    "           kernel_regularizer=l2(5e-4)),\n",
    "    Conv2D(32, (3, 3), padding='SAME', activation='relu',\n",
    "           kernel_regularizer=l2(5e-4)),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(64, (3,3), padding='SAME', activation='relu',\n",
    "           kernel_regularizer=l2(5e-4)),\n",
    "    Conv2D(64, (3,3), padding='SAME', activation='relu',\n",
    "           kernel_regularizer=l2(5e-4)),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(128, (3,3), padding='SAME', activation='relu',\n",
    "           kernel_regularizer=l2(5e-4)),\n",
    "    Conv2D(128, (3,3), padding='SAME', activation='relu',\n",
    "           kernel_regularizer=l2(5e-4)),\n",
    "    Conv2D(128, (3,3), padding='SAME', activation='relu',\n",
    "           kernel_regularizer=l2(5e-4)),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(256, (1, 1), activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Conv2D(128, (1,1), activation='relu'),\n",
    "    AveragePooling2D(pool_size=(3, 3)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Declare epoch, batch size, optimizer\n",
    "epochs = 30\n",
    "batch_size = 100\n",
    "optimizer = Adam(learning_rate=1e-4, decay = 1e-4/epochs)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[6480,224,224,3] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:GatherV2]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mResourceExhaustedError\u001B[0m                    Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-10-7439df0ca6a1>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m                     \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m                     \u001B[0mvalidation_split\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m                     epochs = epochs)\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;31m# Model save\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\juhyeon park\\anaconda3\\envs\\test_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     64\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_method_wrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_in_multi_worker_mode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 66\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     67\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     68\u001B[0m     \u001B[1;31m# Running inside `run_distribute_coordinator` already.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\juhyeon park\\anaconda3\\envs\\test_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m    795\u001B[0m           data_adapter.train_validation_split((x, y, sample_weight),\n\u001B[0;32m    796\u001B[0m                                               \u001B[0mvalidation_split\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mvalidation_split\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 797\u001B[1;33m                                               shuffle=False))\n\u001B[0m\u001B[0;32m    798\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    799\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdistribute_strategy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mscope\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\juhyeon park\\anaconda3\\envs\\test_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001B[0m in \u001B[0;36mtrain_validation_split\u001B[1;34m(arrays, validation_split, shuffle)\u001B[0m\n\u001B[0;32m   1336\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1337\u001B[0m   train_arrays = nest.map_structure(\n\u001B[1;32m-> 1338\u001B[1;33m       functools.partial(_split, indices=train_indices), arrays)\n\u001B[0m\u001B[0;32m   1339\u001B[0m   val_arrays = nest.map_structure(\n\u001B[0;32m   1340\u001B[0m       functools.partial(_split, indices=val_indices), arrays)\n",
      "\u001B[1;32mc:\\users\\juhyeon park\\anaconda3\\envs\\test_gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001B[0m in \u001B[0;36mmap_structure\u001B[1;34m(func, *structure, **kwargs)\u001B[0m\n\u001B[0;32m    615\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    616\u001B[0m   return pack_sequence_as(\n\u001B[1;32m--> 617\u001B[1;33m       \u001B[0mstructure\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mentries\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    618\u001B[0m       expand_composites=expand_composites)\n\u001B[0;32m    619\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\juhyeon park\\anaconda3\\envs\\test_gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    615\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    616\u001B[0m   return pack_sequence_as(\n\u001B[1;32m--> 617\u001B[1;33m       \u001B[0mstructure\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mentries\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    618\u001B[0m       expand_composites=expand_composites)\n\u001B[0;32m    619\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\juhyeon park\\anaconda3\\envs\\test_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001B[0m in \u001B[0;36m_split\u001B[1;34m(t, indices)\u001B[0m\n\u001B[0;32m   1333\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1334\u001B[0m     \u001B[0mt\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconvert_to_tensor_v2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mt\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1335\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0marray_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgather_v2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mt\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindices\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1336\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1337\u001B[0m   train_arrays = nest.map_structure(\n",
      "\u001B[1;32mc:\\users\\juhyeon park\\anaconda3\\envs\\test_gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    178\u001B[0m     \u001B[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    179\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 180\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    181\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    182\u001B[0m       \u001B[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\juhyeon park\\anaconda3\\envs\\test_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001B[0m in \u001B[0;36mgather_v2\u001B[1;34m(params, indices, validate_indices, axis, batch_dims, name)\u001B[0m\n\u001B[0;32m   4539\u001B[0m       \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4540\u001B[0m       \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 4541\u001B[1;33m       batch_dims=batch_dims)\n\u001B[0m\u001B[0;32m   4542\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4543\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\juhyeon park\\anaconda3\\envs\\test_gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    178\u001B[0m     \u001B[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    179\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 180\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    181\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    182\u001B[0m       \u001B[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\juhyeon park\\anaconda3\\envs\\test_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001B[0m in \u001B[0;36mgather\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m   4522\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msparse_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindices\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4523\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mAttributeError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 4524\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mgen_array_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgather_v2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindices\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   4525\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4526\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\juhyeon park\\anaconda3\\envs\\test_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001B[0m in \u001B[0;36mgather_v2\u001B[1;34m(params, indices, axis, batch_dims, name)\u001B[0m\n\u001B[0;32m   3753\u001B[0m         \u001B[1;32mpass\u001B[0m  \u001B[1;31m# Add nodes to the TensorFlow graph.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3754\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3755\u001B[1;33m       \u001B[0m_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mraise_from_not_ok_status\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3756\u001B[0m   \u001B[1;31m# Add nodes to the TensorFlow graph.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3757\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mbatch_dims\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\juhyeon park\\anaconda3\\envs\\test_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36mraise_from_not_ok_status\u001B[1;34m(e, name)\u001B[0m\n\u001B[0;32m   6651\u001B[0m   \u001B[0mmessage\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmessage\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;34m\" name: \"\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;34m\"\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6652\u001B[0m   \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 6653\u001B[1;33m   \u001B[0msix\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mraise_from\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_status_to_exception\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcode\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   6654\u001B[0m   \u001B[1;31m# pylint: enable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6655\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\juhyeon park\\anaconda3\\envs\\test_gpu\\lib\\site-packages\\six.py\u001B[0m in \u001B[0;36mraise_from\u001B[1;34m(value, from_value)\u001B[0m\n",
      "\u001B[1;31mResourceExhaustedError\u001B[0m: OOM when allocating tensor with shape[6480,224,224,3] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:GatherV2]"
     ]
    }
   ],
   "source": [
    "# Compile and training\n",
    "CNN.compile(loss = \"binary_crossentropy\", optimizer = optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = CNN.fit(train_X, train_Y,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_split=0.1,\n",
    "                    epochs = epochs)\n",
    "\n",
    "# Model save\n",
    "CNN.save(\"./checkpoint\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Draw Plot and Save\n",
    "training_log_plot(history)\n",
    "\n",
    "# Evaluate\n",
    "CNN.evaluate(test_X, test_Y)\n",
    "\n",
    "export_model_summary(CNN, \"LightweightCNN\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}